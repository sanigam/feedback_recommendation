{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abee7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62433bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d18906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for cosine similarity\n",
    "def mag(x): \n",
    "    return np.sqrt(sum(i**2 for i in x))\n",
    "def cossim(embed1,embed2):\n",
    "    return np.dot ( embed1, embed2)/(mag(embed1)*mag(embed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6495c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 768)\n",
      "Say more about this\n",
      "[-0.02749122  0.0038594   0.01216771  0.02630792  0.02266499]\n",
      "You missed something\n",
      "[ 0.00320384 -0.00935981 -0.00158467  0.03046354  0.03646295]\n",
      "What does this tell you about?\n",
      "[ 0.01929869 -0.03846261 -0.00386472  0.04521561  0.00936567]\n",
      "Good job!\n",
      "[-0.01111315  0.03667478  0.02177003 -0.04349593  0.00314289]\n",
      "How does this connect to what you said before?\n",
      "[ 0.04603298 -0.03493194  0.01333391  0.02224684  0.0248211 ]\n",
      "1.0000000189202332\n",
      "0.18575934731374472\n"
     ]
    }
   ],
   "source": [
    "#List of phrases \n",
    "phrases = [\n",
    "'Good job!',\n",
    "'Why?',\n",
    "'This is not quite right, check',\n",
    "'Good question',\n",
    "'Add more detail.',\n",
    "'Explain why this is important.',\n",
    "'What does this tell you about?',\n",
    "'What do you mean?',\n",
    "'Say more about this',\n",
    "'You missed something',\n",
    "'How does this connect to what you said before?',\n",
    "'What does this reveal about the authorâ€™s claim?',\n",
    "'Did we see this idea before, or is this new?',\n",
    "'Can you connect this to your own life?',\n",
    "'What is the deeper meaning here?',\n",
    "'How do you know this?'\n",
    "]\n",
    "   \n",
    "phrases = list(set(phrases))\n",
    "\n",
    "#Embeddings for phrases\n",
    "embeddings_p = model.encode( phrases)\n",
    "\n",
    "#Normalizing Embeddings\n",
    "embeddings_p = embeddings_p / np.linalg.norm(embeddings_p, ord=2, axis=1, keepdims=True)\n",
    "print(embeddings_p.shape)\n",
    "# To print embeddings along with its corresponding phrases below \n",
    "for i in range(len(phrases[:5])):\n",
    "    print(phrases[i])\n",
    "    print(embeddings_p[i][:5])\n",
    "print ( cossim(embeddings_p[0], embeddings_p[0]))\n",
    "print ( cossim(embeddings_p[0], embeddings_p[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ec370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data needs 3 text columns - 1) annotation, 2) student_note & 3) teacher_feedback, for privacy reasons cell output is cleared\n",
    "df = pd.read_csv('./teachers_feedbacks_historical.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787261ba-bc92-49fc-be3d-9bb74537e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66987, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d833b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66987, 768)\n"
     ]
    }
   ],
   "source": [
    "#Embeddings for (raw) teacher's feedback\n",
    "embeddings_f = model.encode(df['teacher_feedback'].values)\n",
    "print(embeddings_f.shape)\n",
    "#Normalizing feed back embeddings\n",
    "embeddings_f = embeddings_f / np.linalg.norm(embeddings_f, ord=2, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "993b3869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66987, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.38102397, 0.182388  , 0.47442174, 0.153306  , 0.2288782 ,\n",
       "       0.15670286, 0.4450034 , 0.51017964, 0.41391277, 0.13697979,\n",
       "       0.35046747, 0.36698267, 0.20331094, 0.5332635 , 0.20964894,\n",
       "       0.3703055 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarity matrix between teacher's raw feed back and feedback prases\n",
    "sim_matrix = np.matmul(embeddings_f, embeddings_p.T)\n",
    "print(sim_matrix.shape)\n",
    "sim_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d4aa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explain why this is important.',\n",
       " 'This is not quite right, check',\n",
       " 'Good question',\n",
       " 'Good job!',\n",
       " 'Good question']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#phrase indices which is most similar to feedback\n",
    "phrases_ind = list(np.argmax(sim_matrix, axis=1))\n",
    "#Mapped phrases for the feedback\n",
    "mapped_phrases = [phrases[i] for i in phrases_ind ]\n",
    "mapped_phrases[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47333a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding columns for mapped phrases and similarity score to the dataframe\n",
    "df['phrases'] = mapped_phrases\n",
    "df['score'] = sim_matrix [np.arange(len(sim_matrix)),  phrases_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a693bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this will have 5 columns 1) annotation, 2) student_note , 3) teacher_feedback, 4) phrases  & 5) score\n",
    "#Score is not used in models but it gives an idea of how a phrase is close to raw feedback\n",
    "df.to_csv('./data_with_mapped_phrases_v2.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fc4ca6588292c25fd5979d5ef28797438c836b4ff6cc721dfcac4314f96e24e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
